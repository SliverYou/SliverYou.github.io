<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[多SSH Key解决方法]]></title>
    <url>%2F2018%2F01%2F01%2F%E5%A4%9ASSH-Key%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[有多个 SSH Key，如何在 SSH 连接时不产生冲突呢？ 在进行多个项目的时候，一般都会一个项目对应一个 SSH Key，算是为了避免冲突吧，也或者是碍于不可抗力因素需要多个 SSH Key… 通常都是使用ssh-keygen命令，一路回车生成 SSH Key： 1ssh-keygen -t rsa 这样在~/.ssh/目录下会默认生成id_rsa.pub和id_rsa文件，也就是公钥和私钥。 为了各自需要，有时候需要创建第二个 SSH Key： 1ssh-keygen -t rsa 在第一个返回结果下输入第二个 SSH Key 的名称，比如： 12Generating public/private rsa key pair.Enter file in which to save the key (/Users/sliver/.ssh/id_rsa): /Users/sliver/.ssh/id_second_rsa 输入密码可以选择回车跳过，然后将在.ssh目录下生成名称为id_second_rsa.pub和id_second_rsa的公钥和私钥。 之后在终端输入以下命令，将私钥添加到 ssh-agent 中： 12ssh-add ~/.ssh/id_rsassh-add ~/.ssh/id_second_rsa 如果有良好的密钥命名习惯的话可以直接输入： 1ssh-add ~/.ssh/*_rsa 一步到位，可以任意穿梭于多个SSH连接中了。 可使用ssh-add -l查看添加私钥的结果如何： 122048 SHA256:S97ZYNIuP0qqdDSBQLP6LD/2rGBgDlWCDyb2B3La1U0 /Users/sliver/.ssh/id_rsa (RSA)2048 SHA256:JWEstYUqxRK5tK2NVj17imvkaIN4kXTL7DSImImbmbI /Users/sliver/.ssh/id_second_rsa (RSA) 一般出现以上结果就对了。出问题时，可使用ssh-add -d删除指定私钥，或者ssh-add -D删除所有私钥，重新再来一遍即可。 在重启 PC 后，都要重新手动添加私钥到 ssh-agent，显然这是有些麻烦或是容易遗忘的。可以在 Shell 配置文件中，我是在~/.zshrc下，末尾添加： 1ssh-add ~/.ssh/*_rsa 以后终端也就可以自动添加私钥了，大功告成。 最后啰嗦一下 生成 Key 时，可能会需要添加自己的邮箱当做备注，可添加-C参数： 1ssh-keygen -t rsa -C &quot;your_email@gmail.com&quot; 在生成的公钥文件中可以看到添加的备注，自己去找找吧 hhh。]]></content>
      <categories>
        <category>方法</category>
      </categories>
      <tags>
        <tag>Tips</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Delicious Cookie]]></title>
    <url>%2F2017%2F12%2F29%2F%E5%A5%BD%E5%90%83%E7%9A%84Cookies%2F</url>
    <content type="text"><![CDATA[Cookie是什么？好吃么？ 一个 Cookie 就是存储在用户主机浏览器中的一小段文本文件。Cookie 是纯文本形式，它们不包含任何可执行代码。一个 Web 页面或服务器告知浏览器来将这些信息存储并且基于一系列规则在之后的每个请求中都将该信息返回至服务器。Web 服务器之后可以利用这些信息来标识用户。 上面是科普，这里随便说说。其实要说 Cookie ，就要说它所立足的 HTTP 协议。HTTP 是无状态协议，它不对之前发生过的请求和响应的状态进行管理。也就是说，无法根据之前的状态进行本次的请求处理。那么就会发生这种情况： 假设要求登录认证的 Web 页面本身无法进行状态的管理（不记录已登录的状态），那么每次跳转新页面就要再次登录，或者要在每次请求报文中附加参数来管理登录状态。 是不是很麻烦？不过不可否认，无状态协议当然也有它的优点。由于不必保存状态，自然可减少服务器的 CPU 及内存资源的消耗。从另一侧面来说，也正是因为 HTTP 协议本身是非常简单的，所以才会被应用在各种场景里。 所以，为了保留无状态协议这个特征的同时又要解决类似的矛盾问题，于是引入了 Cookie 技术。Cookie 技术通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。 Cookie 会根据从服务器端发送的响应报文内的一个叫做 Set-Cookie 的首部字段信息，通知客户端保存 Cookie。当下次客户端再往该服务器发送请求时，客户端会自动在请求报文中加入 Cookie 值后发送出去。 服务器端发现客户端发送过来的 Cookie 后，会去检查究竟是从哪一个客户端发来的连接请求，然后对比服务器上的记录，最后得到之前的状态信息。 概括下来，其实就是服务器为了辨别每个用户，就给客户端们颁发一个通行证，一人一个，无论谁访问都必须携带自己的通行证。这样服务器就能从通行证上确认客户身份了，这也就是 Cookie 的工作原理。 为什么突然说 Cookie 呢？因为之前爬教务系统，都是使用 requests 的 session 一口气保持会话的，很少去管 Cookie 的事，分模块和函数式编程的时候，才发现会话的中断和接下来请求的失败…所以特地补全一下知识漏洞吧 hhh。 首先，查看 requests 的官方文档： 123456789class requests.cookies.RequestsCookieJar(policy=None)[source]Compatibility class; is a cookielib.CookieJar, but exposes a dict interface.This is the CookieJar we create by default for requests and sessions that don&apos;t specify one, since some clients may expect response.cookies and session.cookies to support dict operations.Requests does not use the dict interface internally; it&apos;s just for compatibility with external client code. All requests code should work out of the box with externally provided instances of CookieJar, e.g. LWPCookieJar and FileCookieJar.Unlike a regular CookieJar, this class is pickleable. 差不多知道了 cookies 对象是 CookieJar、FileCookieJar、MozillaCookieJar、LWPCookieJar等。各个 CookieJar 的关系是：CookieJar —-派生—-&gt;FileCookieJar —-派生—–&gt;MozillaCookieJar 和 LWPCookieJar 再查看 http.cookiejar — Cookie handling for HTTP clients 中 MozillaCookieJar 和 LWPCookieJar 的官方介绍： 123456789101112131415The following CookieJar subclasses are provided for reading and writing.class http.cookiejar.MozillaCookieJar(filename, delayload=None, policy=None) A FileCookieJar that can load from and save cookies to disk in the Mozilla cookies.txt file format (which is also used by the Lynx and Netscape browsers). Note This loses information about RFC 2965 cookies, and also about newer or non-standard cookie-attributes such as port. Warning Back up your cookies before saving if you have cookies whose loss / corruption would be inconvenient (there are some subtleties which may lead to slight changes in the file over a load / save round-trip). Also note that cookies saved while Mozilla is running will get clobbered by Mozilla.class http.cookiejar.LWPCookieJar(filename, delayload=None, policy=None) A FileCookieJar that can load from and save cookies to disk in format compatible with the libwww-perl library’s Set-Cookie3 file format. This is convenient if you want to store cookies in a human-readable file. 可见，MozillaCookieJar 和 LWPCookieJar 可对文件进行 Cookie 的存取改动。 可以开始练练手了，先利用 LWPCookieJar 对象实现存取 Cookie 到文件的功能： 12345678910111213141516171819import requests, sysfrom http.cookiejar import LWPCookieJar as Cookiefrom requests.exceptions import RequestExceptionheaders = &#123; "User-Agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"&#125;s = requests.Session()# 声明一个 LWPCookieJar 对象s.cookies = Cookie()try: html = s.get("http://cas.hdu.edu.cn/cas/login",headers=headers,timeout=5)except RequestException: print("请求超时！请检查网络后再次尝试！") sys.exit(1)# 将获取到的 Cookie 存入文件中s.cookies.save('cookies.txt',ignore_discard=True,ignore_expires=True) save 方法中的两个参数的官方解释是： gnore_discard: save even cookies set to be discarded. ignore_expires: save even cookies that have expiredThe file is overwritten if it already exists 显然 ignore_discard 的意思是即使 Cookie 将会被丢弃也要将它保存下来，ignore_expires 的意思是如果在该文件中 Cookie 已经存在，则覆盖原文件写入，在这里，如果两个全部设置为True，运行之后，Cookie 将会被保存到 cookies.txt 文件中。 成功后我们可以找到新建立的 cookies.txt 文件，打开可看到获取的 Cookie： 123#LWP-Cookies-2.0Set-Cookie3: key_dcp_cas=&quot;vK8zhGgBzT8S1QHcgnypKRpRxTny1B1LM20Cmcn8SfMtw2ch2QxG!-1218671341&quot;; path=&quot;/&quot;; domain=&quot;cas.hdu.edu.cn&quot;; path_spec; discard; HttpOnly=None; version=0Set-Cookie3: route=c4983b7b52b1d14e475c56063c71cbb3; path=&quot;/&quot;; domain=&quot;cas.hdu.edu.cn&quot;; path_spec; discard; version=0 现在可以试试从文件读取 Cookie 了： 12345678910111213141516import requestsfrom http.cookiejar import LWPCookieJar as Cookiedef load_cookies(): s = requests.session() s.cookies = Cookie() # 从文件读取 Cookie s.cookies.load('cookies.txt',ignore_discard=True,ignore_expires=True) return ss = load_cookies()# 直接打印 Cookieprint(s.cookies)dict = requests.utils.dict_from_cookiejar(s.cookies)# 打印字典形式的 Cookieprint(dict) 返回结果如下： 123&lt;LWPCookieJar[&lt;Cookie key_dcp_cas=vK8zhGgBzT8S1QHcgnypKRpRxTny1B1LM20Cmcn8SfMtw2ch2QxG!-1218671341 for cas.hdu.edu.cn/&gt;, &lt;Cookie route=c4983b7b52b1d14e475c56063c71cbb3 for cas.hdu.edu.cn/&gt;]&gt;&#123;&apos;key_dcp_cas&apos;: &apos;vK8zhGgBzT8S1QHcgnypKRpRxTny1B1LM20Cmcn8SfMtw2ch2QxG!-1218671341&apos;, &apos;route&apos;: &apos;c4983b7b52b1d14e475c56063c71cbb3&apos;&#125; 之后只要 Cookie 还在生存期内，就可以进教务网站利用Cookie 爬成绩、爬课表等，还是挺不错的。 Cookie 就讲这么多吧，以后用到更高级的方法再补充。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Notes</tag>
        <tag>Cookie</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux服务器基础配置]]></title>
    <url>%2F2017%2F12%2F26%2FLinux%E5%9F%BA%E7%A1%80%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[最近需要去配置服务器，所以可以先拿虚拟机练练手，并分享一下自己的配置过程。 首先，你一定会问：Linux有什么作用呢？可以归类为四点： 商业服务器基本都是Linux 开源软件都先支持Linux 大数据分析、机器学习首选Linux 整个互联网地基靠Linux撑起来 强大如斯，不得不用。为了去学Linux，首先需要忘掉Windows的东西： Linux下是没有exe形式的程序的 文件名等大小写在Linux下是需要区分的 Linux下，一切皆文件 文件的后缀名并不是必须要的，它只是为了找到正确的打开方式而已 更多资料，参见百度百科：Linux 百度百科 为了使用Linux，可以先去下载虚拟机。 虚拟机（Virtual Machine）指通过软件模拟的具有完整硬件系统功能的、运行在一个完全隔离环境中的完整计算机系统。 简单来说，其实就是通过虚拟机可以在自己的电脑上安装另一个操作系统，而不会影响原系统。比如，做渗透的人，一般就会在虚拟机下用Kali Linux去做专业的渗透测试。Mac平台下，可以使用Parallels Desktop虚拟机软件。 Parallels Desktop是一款运行在 Mac 电脑上的极为优秀的虚拟机软件。用户可以在 Mac OS X 下非常方便运行 Windows、Linux 等操作系统及应用。用户不必繁琐重复地重启电脑即可在 Win 与 Mac 之间切换甚至同时使用它们。 各位可以Google一下各种资源，涉及版权问题，就不多提了。 虚拟机软件安装并配置CentOS CentOS下载： 装好虚拟机后，就可以开始装Linux系统了，这里装的是CentOS。安装推荐网易镜像(后续可能还有更新版本，以最新版本为准)：http://mirrors.163.com/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1708.iso下载完毕后，我是使用Parallels Desktop进行无脑安装的，新手指导还是挺简单的。安装完毕后，可以开始大干一场了。 配置网络： 终端输入： 1vi /etc/sysconfig/network-scripts/ifcfg- 按住Tab，补充显示的第一个文件名，我的是ifcfg-eth0即最后的命令是： 1vi /etc/sysconfig/network-scripts/ifcfg-eth0 按i插入文字，找到ONBOOT一栏将其对应的值改成yes，按esc后输入:wq退出编辑。现在回到终端输入： 1service network restart 这个时候再输入ip addr可以看到启动网络服务后的ip地址了。 安装网络工具包 1yum install net-tools 安装成功后在Parallels界面将CentOS的网络设置为桥接网络，再使用ifconfig命令查看ip。 1234567891011121314151617eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 192.168.3.12 netmask 255.255.255.0 broadcast 192.168.3.255 inet6 fe80::21c:42ff:fe50:f6f9 prefixlen 64 scopeid 0x20&lt;link&gt; ether 00:1c:42:50:f6:f9 txqueuelen 1000 (Ethernet) RX packets 32807 bytes 44041713 (42.0 MiB) RX errors 0 dropped 3 overruns 0 frame 0 TX packets 13811 bytes 1092135 (1.0 MiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 inet6 ::1 prefixlen 128 scopeid 0x10&lt;host&gt; loop txqueuelen 1 (Local Loopback) RX packets 72 bytes 6248 (6.1 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 72 bytes 6248 (6.1 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 192.168.3.12就是我们需要的ip了(当然ip肯定各不相同)。 替换默认源 网易CentOS镜像使用帮助： http://mirrors.163.com/.help/centos.html 首先查看我们当前的CentOS版本： 1cat /etc/redhat-release 我的是7.4版本，所以返回结果是： 1CentOS Linux release 7.4.1708 (Core) 知道版本后先去下载wget，这里分享一下wget的资料： wget 是一个从网络上自动下载文件的自由工具，支持通过 HTTP、HTTPS、FTP 三个最常见的 TCP/IP协议 下载，并可以使用 HTTP 代理。”wget” 这个名称来源于 “World Wide Web” 与 “get” 的结合。 现在开始下载： 1sudo yum install wget 按照网易镜像帮助的提示，先cd到yum.repos.d目录： 1cd /etc/yum.repos.d/ 这个时候复制响应版本的源镜像链接，再wget下载： 1sudo wget http://mirrors.163.com/.help/CentOS7-Base-163.repo 替换完毕后，依次输入以下两个命令，生成缓存： 12yum clean allyum makecache 这样可以快速下载vim了： 1sudo yum install vim 使用oh-my-zsh 获取配置zsh zsh是一个很强的shell，拥有很多强劲的功能，它的的命令补全功能非常强大，可以补齐路径、补齐命令、补齐参数等，而且还有强大的别名功能，总之，一定好用。 zsh详细介绍 现在，开始配置zsh吧。可以先查看目前CentOS的默认shell： 1echo $SHELL 返回结果如下： 1/bin/bash 果然不是zsh哈哈。那不死心再看看bin下有没有zsh： 1cat /etc/shells 返回结果如下： 123456/bin/sh/bin/bash/sbin/nologin/bin/dash/bin/tcsh/bin/csh 好吧，还是没有…那自己去下吧。 1sudo yum -y install zsh 再去看看bin目录： 1cat /etc/shells 1234567/bin/sh/bin/bash/sbin/nologin/bin/dash/bin/tcsh/bin/csh/bin/zsh 已经有zsh了，将其替换为默认shell吧： 1sudo chsh -s /bin/zsh 重启一下： 1reboot 重新打开CentOS，看看默认shell： 1echo $SHELL 1/bin/zsh 成功。 获取oh-my-zsh 首先当然是要安装git了： 1sudo yum -y install git 成功后下载oh-my-zsh： 1sudo wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 成功后会显示如下界面： 1234567891011 __ __ ____ / /_ ____ ___ __ __ ____ _____/ /_ / __ \/ __ \ / __ `__ \/ / / / /_ / / ___/ __ \ / /_/ / / / / / / / / / / /_/ / / /_(__ ) / / / \____/_/ /_/ /_/ /_/ /_/\__, / /___/____/_/ /_/ /____/ ....is now installed!Please look over the ~/.zshrc file to select plugins, themes, and options.p.s. Follow us at https://twitter.com/ohmyzsh.p.p.s. Get stickers and t-shirts at http://shop.planetargon.com. 还挺cool的哈哈。 更改主题 先cd到.zshrc所在目录： 12cd ~vim .zshrc 找到ZSH_THEME修改为agnoster(agnoster是我一直比较喜欢的主题)： 1ZSH_THEME="agnoster" 保存启用修改： 1source ~/.zshrc vim配色 终端还有vim还是赏心悦目的好，先下载Solarized： 1git clone git://github.com/altercation/solarized.git 颜色配置一下： 1234cd solarizedcd vim-colors-solarized/colorsmkdir -p ~/.vim/colorscp solarized.vim ~/.vim/colors/ 再去给vim配置一下吧：vim ~/.vimrc这里我加入了一些简单的vim自定义配置： 1234567891011121314151617syntax enableset background=darkcolorscheme solarizedset showmatch " 高亮显示对应的括号set number " 显示行号set cindent " C风格的对齐方式set autoindent " 自动对齐set confirm " 在处理未保存或只读文件的时候，弹出确认set tabstop=4 " Tab键的宽度syntax on " 自动语法高亮set softtabstop=4set shiftwidth=4 " 统一缩进为4set hlsearchset incsearch " 搜索逐字符高亮set gdefault " 行内替换set encoding=utf-8set completeopt=preview,menu 这样我们基本的Linux配置服务就完成了。 Mac利用SSH连接CentOS SSH工具 SSH 为 Secure Shell 的缩写，由 IETF 的网络小组（Network Working Group）所制定；SSH 为建立在应用层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。SSH最初是UNIX系统上的一个程序，后来又迅速扩展到其他操作平台。SSH在正确使用时可弥补网络中的漏洞。SSH客户端适用于多种平台。几乎所有UNIX平台—包括HP-UX、Linux、AIX、Solaris、Digital UNIX、Irix，以及其他平台，都可运行SSH。 总而言之，SSH是为本地的客户端与服务器上的服务端相互之间进行远程登录会话提供安全的的协议。 服务器安装SSH服务 一般Linux的桌面发行版，即有GUI界面的发行版是没有安装SSH服务端的，可以使用如下命令安装： 1sudo yum install openssh-server 启动SSH： 1service sshd start 查看是否启动： 1ps -ef |grep ssh 成功就可以看到这个进程了： 1&gt;&gt;&gt;root 1300 1 0 04:29 ? 00:00:00 /usr/sbin/sshd -D 设置开机运行： 1chkconfig sshd on 本地安装SSH服务 Linux平台可以使用如下命令： 1sudo yum install openssh-clients Mac直接使用iTerm2就行了，还可以尝试一下SSH连接： 1ssh sliver@192.168.3.12 输入服务器账户密码即可成功连接了。 使用ssh-copy-id-for-OSX工具将公钥复制至ssh服务器 每次连接都要输入密码还是挺麻烦的，可以使用公钥登录的方法，免去每次都要输入密码的烦恼。 公钥登录是为了解决每次登录服务器都要输入密码的问题，流行使用RSA加密方案，主要流程包含： 1.客户端生成RSA公钥和私钥2.客户端将自己的公钥存放到服务器3.客户端请求连接服务器，服务器将一个随机字符串发送给客户端4.客户端根据自己的私钥加密这个随机字符串之后再发送给服务器5.服务器接受到加密后的字符串之后用公钥解密，如果正确就让客户端登录，否则拒绝。 这样也就不用使用密码了。那么，第一步当然是要生成公钥和秘钥了，在用户主目录下输入： 1ssh-keygen 直接一直回车到结束，生成的公钥和秘钥已经就在~/.ssh/目录下了，id_rsa.pub即为所要的公钥。现在可以将公钥放到服务器上，这里使用一种比较简单的方法： 1234567brew install ssh-copy-idssh-copy-id username@hostname # 将username和hostname替换为你的ssh服务器用户名和IP# 不加参数默认使用~/.ssh/id_rsa.pub# 添加-i参数可以自定义添加的公钥ssh-copy-id -i ~/.ssh/id_rsa.pub username@hostname 使用ssh-copy-id，可以将公钥自动保存到服务器用户目录下的/.ssh/authorized_keys文件中去，当然自己在服务器手动创建并复制粘贴公钥也是可以的。以后使用ssh登录服务器就不用再输入密码了： 1234ssh sliver@192.168.3.12&gt;&gt;&gt;Last login: Mon Dec 25 14:12:03 2017 from 192.168.3.5[sliver@localhost ~]$ 可以输入exit退出ssh连接。但还是要输入一大串不太好记的字符串，在zsh下可以使用别名： 12echo "alias ssh-to-username='ssh username@hostname'" &gt;&gt; ~/.zshrc #将username和hostname替换为你的服务器信息source ~/.zshrc 看看怎么样： 1234ssh-to-centos&gt;&gt;&gt;Last login: Mon Dec 25 14:17:31 2017 from 192.168.3.5[sliver@localhost ~]$ 也可以在~/.ssh/目录下创建config文件，添加如下代码： 1234Host alias_name HostName ip_address Port 22(默认) User user_name 我是这样添加的： 1234Host centos HostName 192.168.3.12 Port 22 User sliver 使用如下命令进行远程连接： 1ssh centos 舒服多了。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Tips</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3爬虫相关库笔记]]></title>
    <url>%2F2017%2F12%2F14%2FPython3%E7%88%AC%E8%99%AB%E7%9B%B8%E5%85%B3%E5%BA%93%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[有时候一个爬虫程序，可能只有几行代码，但是它涉及到的知识面却很广，这里先记下一些相关知识，以此共勉。 JSON什么是 JSON ？JSON 指的是 JavaScript 对象表示法 (JavaScript Object Notation） JSON 是轻量级的文本数据交换格式 JSON 独立于语言 JSON 具有自我描述性，更易理解 JSON 使用 JavaScript 语法来描述数据对象，但是 JSON 仍然独立于语言和平台。JSON 解析器和 JSON 库支持许多不同的编程语言。 JSON 有什么优点？ 方便于传输，较少冗余的字符。当然直接传二进制是最好的，但面临难解析的问题。亦可以是 XML、纯字符串的方式，但 JSON 有其独到的好处。有兴趣可了解一下。 方便转换。有很多的 JSON API 提供了 JSON 字符串转成对象、对象转换成 JSON 串的方法。 易于阅读。JSON 代码的良好结构，可以很直观地了解存的是什么内容。 简而言之，JSON 就是比 XML 的基础上，去掉了标签，这样也就节省了大量的存储空间。 Python中的JSON模块 json 模块提供了一种很简单的方式来编码和解码 JSON 数据。其中两个主要的函数是 json.dumps() 和 json.loads()，要比其他序列化函数库如 pickle 的接口少得多。下面演示如何将一个 Python 数据结构转换为 JSON： 12345678910import jsondata = &#123; 'name' : 'ACME', 'shares' : 100, 'price' : 542.23&#125;json_str = json.dumps(data)print(json_str) 12#返回结果&#123;"name": "ACME", "shares": 100, "price": 542.23&#125; 下面演示如何将一个 JSON 编码的字符串转换回一个 Python 数据结构： 123&gt;&gt;&gt; data = json.loads(json_str)&gt;&gt;&gt; print(data)&#123;'name': 'ACME', 'shares': 100, 'price': 542.23&#125; 如果要处理的是文件而不是字符串，可以使用 json.dump() 和 json.load() 来编码和解码 JSON 数据。例如： 1234567# Writing JSON datawith open('data.json', 'w') as f: json.dump(data, f)# Reading data backwith open('data.json', 'r') as f: data = json.load(f) JSON编码支持的基本数据类型为 None，bool，int，float 和 str，以及包含这些类型数据的 lists，tuples 和 dictionaries。 对 dictionaries，keys 需要是字符串类型(字典中任何非字符串类型的key在编码时会先转换为字符串)。为了遵循 JSON 规范，你应该只编 Python 的 lists 和 dictionaries。而且，在 Web 应用程序中，顶层对象被编码为一个字典是一个标准做法。 JSON 编码的格式对于 Python 语法而已几乎是完全一样的，除了一些小的差异之外。比如，True 会被映射为 true，False 被映射为 false，而 None 会被映射为 null。下面是一个例子，演示了编码后的字符串效果： 1234567&gt;&gt;&gt; json.dumps(False)'false'&gt;&gt;&gt; d = &#123;'a': True,... 'b': 'Hello',... 'c': None&#125;&gt;&gt;&gt; json.dumps(d)'&#123;"b": "Hello", "c": null, "a": true&#125;' 总结 JSON字符串转为字典 json.load / json.loads两个方法功能类似，可选参数也相同，最大的区别在于，json.load 方法接受的输入，即第一个参数，是包含 JSON 数据的文件对象，如 open 方法的返回对象。json.loads 接受的输入是 JSON 字符串，而非文件对象。从输入类型的区别也可以看出两者的使用场合。可选参数包括是否需要转换整型、浮点型等数值的参数，还有一些复杂的功能，暂时没有用到，以后有机会再了解。 字典转换为JSON json.dump / json.dumps对应于 load 和 loads，dump 的第一个参数是对象字典，第二个参数是文件对象，可以直接将转换后的 JSON 数据写入文件，dumps 的第一个参数是对象字典，其余都是可选参数。dump 和 dumps 的可选参数相同，这些参数都相当实用，现将用到的参数记录如下： ensure_ascii 默认为 True，保证转换后的 JSON 字符串中全部是 ascii 字符，非 ascii 字符都会被转义。如果数据中存在中文或其他非 ascii 字符，最好将 ensure_ascii 设置为 False，保证输出结果正常。 indent 缩进，默认为 None ，没有缩进，设置为正整数时，输出的格式将按照 indent 指定的半角空格数缩进，相当实用。 separators 设置分隔符，默认的分隔符是(‘,’, ‘: ‘)，如果需要自定义 JSON 中的分隔符，例如调整冒号前后的空格数，可以按 (item_separator, key_separator) 的形式设置。 sort_keys 默认为 False，设为 True 时，输出结果将按照字典中的 key 排序。 1234567# 举例&gt;&gt;&gt; print(json.dumps(data, indent=4))&#123; "name": "ACME", "shares": 100, "price": 542.23&#125; DemjsonDemjson 是 Python 的第三方模块库，可用于编码和解码 JSON 数据，包含了 JSON 的格式化及校验功能。安装命令很简单，一个命令就可以搞定了： 1pip3 install demjson 现在来使用一下： 123456789101112131415import demjsondata = &#123; 'name' : 'ACME', 'shares' : 100, 'price' : 542.23&#125;json_str = demjson.encode(data) # 转换为JSON字符串print(json_str)text = demjson.decode(json_str) # 转换为字典print(text)&gt;&gt;&gt;&#123;"name":"ACME","price":542.23,"shares":100&#125;&gt;&gt;&gt;&#123;'name': 'ACME', 'price': 542.23, 'shares': 100&#125; Hashlibhashlib 是一个提供了一些流行的hash算法的 Python 标准库，其中所包括的算法有 md5，sha1，sha224，sha256，sha384，sha512。另外，模块中所定义的 new(name, string=”) 方法可通过指定系统所支持的hash算法来构造相应的 hash 对象。Python3 中 hashlib 模块代替了 Python2 中的 md5 和 sham 模块，使用这个模块一般分为3步： 创建一个哈希对象，使用哈希算法命名的构造函数或通用构造函数来创建。 使用哈希对象调用 update() 方法填充这个对象。 调用 digest() 或 hexdigest() 方法来获取摘要（加密结果）。 md5 加密： 12345678# md5加密import hashlibhash = hashlib.md5()hash.update('sliver'.encode('utf-8'))print(hash.hexdigest())&gt;&gt;&gt;241f166bdf9887f732ae06ba859da376 也可以这样实现 md5 加密： 123456789101112import hashlibhash1 = hashlib.md5(b'sliver')print(hash1.hexdigest())hash2 = hashlib.md5('sliver'.encode('utf-8'))print(hash2.hexdigest())# 也就是加密前必须先指定编码&gt;&gt;&gt;241f166bdf9887f732ae06ba859da376&gt;&gt;&gt;241f166bdf9887f732ae06ba859da376 sha1 加密： 12345678# sha1加密import hashlibhash = hashlib.sha1()hash.update('sliver'.encode('utf-8'))print(hash.hexdigest())&gt;&gt;&gt;e7896b82b9fcccbba18d905c0e374c4e8d612b08 sha256 加密： 12345678# sha256加密import hashlibhash = hashlib.sha256()hash.update('sliver'.encode('utf-8'))print(hash.hexdigest())&gt;&gt;&gt;66cb86b497f2b457cc6a19fafda4952bfbd831ed9c2d7ba12157ef269ecf3885 sha512 加密： 12345678# sha512加密import hashlibhash = hashlib.sha512()hash.update('sliver'.encode('utf-8'))print(hash.hexdigest())&gt;&gt;&gt;f3e8498d2d0b2a91cc29e085ca22c4ca27345633b023ba8ec83430784ee715a9bb5a27e758ce04eb7b653c079e7264753fc313d7eb5df352e43e34c324d88bf0 “加盐”加密： 以上的算法确实是密码学大佬们的结晶，但比如sha1算法还是可以通过暴力破解被破解出来的，这时候，自己自定义加上key，俗称“加盐”，能让加密算法更加安全。 12345678# “加盐”加密import hashlibhash = hashlib.md5('ariel'.encode('utf-8'))hash.update('sliver'.encode('utf-8'))print(hash.hexdigest())&gt;&gt;&gt;077ee0a6276e80b65a42de44a27b9f08 GetPass众所周知，Linux 系统下，在终端输入密码时，是不显示密码位数的（不回显）。这也告诉我们：为了安全，核心的操作应该要设为不可见的。Python 也为我们提供了类似功能的库，getpass。它的核心代码很短，却很有用。 首先看看模块中主要的两个函数的 API 和介绍: getpass.getpass(prompt=&#39;Password: &#39;, stream=None) 1234567891011Prompt the user for a password without echoing. The user is prompted using the string prompt, which defaults to &apos;Password: &apos;.On Unix, the prompt is written to the file-like object stream using the replace error handler if needed. stream defaults to the controlling terminal (/dev/tty) or if that is unavailable to sys.stderr (this argument is ignored on Windows).If echo free input is unavailable getpass() falls back to printing a warning message to stream and reading from sys.stdin and issuing a GetPassWarning.Note: If you call getpass from within IDLE, the input may be done in the terminal you launched IDLE from rather than the idle window itself.exception getpass.GetPassWarningA UserWarning subclass issued when password input may be echoed. 调用该函数可以在命令行窗口里无回显输入密码。参数 prompt 代表提示字符串，默认是Password:，有点类似 input。在 Unix 系统中，stream 默认为当前控制的终端。而在 Windows 系统中 stream 参数会被忽略掉，默认使用 stdin，另外在 IDLE 下使用 getpass 的话，一般会转换成终端来运行脚本。如果无法正常使用 getpass，会引发一个 GetPassWarning 错误，然后模块会使用有回显的输入模式读取数据。 getpass.getuser() 12345Return the “login name” of the user.This function checks the environment variables LOGNAME, USER, LNAME and USERNAME, in order, and returns the value of the first one which is set to a non-empty string. If none are set, the login name from the password database is returned on systems which support the pwd module, otherwise, an exception is raised. 通过这个函数可以去 Shell 的环境变量中获取当前用户名。 动手试试吧： 123456import getpassuser = getpass.getuser()print('Hello,',user)password = getpass.getpass('Please enter your password: ')print("Your password is:", password) 返回结果如下： 123Hello, sliverPlease enter your password:Your password is: 123456 PrettyTablePrettyTable 是 Python 的第三方模块，需要手动下载： 1pip install prettytable 这个模块可以将数据输出的如表格一般好看、整齐，很适合强迫症患者 hhh。现在来使用一下吧： 1234567from prettytable import PrettyTable as pttable = pt(["姓名", "性别", "成绩"])table.add_row(["Sliver", "男", 95])table.add_row(["Ariel", "女", 99])table.add_row(["Hollen", "男", 80])print(table) 结果如下： 总结 想要创建一个表，先进行初始化： 123from prettytable import PrettyTable as pttable = pt() 接下来就是添加表中的元素了： 123456# 按行添加table = pt(["姓名", "性别", "成绩"])table.add_row(["Sliver", "男", 95])table.add_row(["Ariel", "女", 99])table.add_row(["Hollen", "男", 80])print(table) 按行添加时，列表要在初始化时就要插入一个列表当做表头，否则 PrettyTable 会使用Field 1 | Field 2 | Field 3依次进行表头填充。 123456# 按列添加table = pt()table.add_column("姓名", ["Sliver", "Ariel", "Hollen"])table.add_column("性别", ["男", "女" ,"男"])table.add_column("成绩", [95, 99, 80])print(table) 按列添加时，不需要对表头进行初始化，但是插入列时，要添加要插入的列的名称。 其他功能 无表格框输出： 1print(pt.get_string()) 可将表按某列数值进行排序： 1print(table.get_string(sortby="成绩", reversesort=True)) 想了解更多功能可转到 Python PrettyTable 模块 FunctoolsFunctools 是一个很厉害的库，看看官方的介绍： 123The functools module is for higher-order functions: functions that act on or return other functions. In general, any callable object can be treated as a function for the purposes of this module. 简单来说，functools 是面向高阶函数的函数：指那些作用于函数或者返回其他函数的函数。通常情况下，只要是可以被当做函数调用的对象就是这个模块的目标。 这里主要介绍该模块的 partial() 函数。 partial() 函数是将所要承载的函数作为 partial() 函数的第一个参数，原函数的各个参数依次作为partial() 函数后续的参数，当然也可以使用关键字参数来赋值。 有时候函数的参数个数可能会很多，但在后续使用时，我们已经知道要一直使用这个参数，就可以使用 partial() 函数来简化函数。partial() 可以创建一个新的函数，这个新函数可以固定住原函数的全部或部分参数，从而在调用函数时更简单。 这里附上用于简化 BeautifulSoup 的例子： 12345678910111213141516import requests, sysfrom requests.exceptions import RequestExceptionfrom functools import partialfrom bs4 import BeautifulSoupheaders = &#123; "User-Agent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36"&#125;bs = partial(BeautifulSoup, features='html5lib')s = requests.Session()try: html = s.get("http://cas.hdu.edu.cn/cas/login", headers=headers, timeout=5) print(bs(html.text).prettify())except RequestException: print("请求超时!请检查网络后再次尝试!") sys.exit(1) 查看更多函数：Python functools模块学习总结 Python 中的函数eval(str) eval(str) 函数很强大，它是 Python 用于执行字符串内的表达式的一个内置函数，使用 eval，可以很方便的将字符串动态执行。 eval() 函数常见作用有： 1、计算字符串中有效的表达式，并返回结果 123456&gt;&gt;&gt; eval('pow(2,2)')4&gt;&gt;&gt; eval('2 + 2')4&gt;&gt;&gt; eval("4 * 4")16 2、将字符串转成相应的 Python 对象（如 list、tuple、dict 和 string 之间的转换） 123456789101112&gt;&gt;&gt; a = "[[1,2], [3,4], [5,6], [7,8], [9,0]]"&gt;&gt;&gt; b = eval(a)&gt;&gt;&gt; b[[1, 2], [3, 4], [5, 6], [7, 8], [9, 0]]&gt;&gt;&gt; a = "&#123;1:'xx',2:'yy'&#125;"&gt;&gt;&gt; c = eval(a)&gt;&gt;&gt; c&#123;1: 'xx', 2: 'yy'&#125;&gt;&gt;&gt; a = "(1,2,3,4)"&gt;&gt;&gt; d = eval(a)&gt;&gt;&gt; d(1, 2, 3, 4) 3、将利用反引号转换的字符串再反转回对象 12345678910&gt;&gt;&gt; list1 = [1,2,3,4,5]&gt;&gt;&gt; `list1`'[1, 2, 3, 4, 5]'&gt;&gt;&gt; type(`list1`)&lt;type 'str'&gt;&gt;&gt;&gt; type(eval(`list1`))&lt;type 'list'&gt;&gt;&gt;&gt; a = eval(`list1`)&gt;&gt;&gt; a[1, 2, 3, 4, 5] 尾声先写这么多吧，未完待续。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Notes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3爬虫之urllib模块的使用]]></title>
    <url>%2F2017%2F12%2F07%2FPython3%E7%88%AC%E8%99%AB%E4%B9%8Burllib%E6%A8%A1%E5%9D%97%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[今天来说说python3内置的一个HTTP请求库，urllib。 官方文档：urllib — URL handling modules urllib中包括了四个模块，包括了：urllib.request，urllib.error，urllib.parse，urllib.robotparser urllib.request (请求模块)：可以用来发送request和获取request的结果 urllib.error (异常处理模块)：包含了urllib.request产生的异常 urllib.parse (URL解析模块)：用来解析和处理URL urllib.robotparse (robots.txt解析模块)：用来解析页面的robots.txt文件 显而易见，urllib.request库和urllib.error库是在一次模拟请求中比较重要的库。 使用urllib.request发送请求 简单urllib.request.urlopen()使用方法 urllib.request模块提供了最基本的构造HTTP请求的方法，利用它可以模拟浏览器的一个请求发起过程，同时它还带有处理authenticaton(授权验证)，redirections(重定向)，cookies(浏览器Cookies)以及其它内容。首先，先试着抓取一下百度的页面： 1234import urllib.request response = urllib.request.urlopen("http://www.baidu.com") print(response.read().decode("utf-8")) 真正的代码其实只有两行，我们便完成了对百度首页的抓取，并输出了它的网页源代码。在爬虫程序中，得到了网页源代码之后，你所需要的链接、图片、视频、文本信息等就可以在网页源代码中查找并提取出来。现在尝试利用type函数输出response的类型： 1234import urllib.request response = urllib.request.urlopen("http://www.baidu.com") print(type(response)) 输出结果为：&lt;class &#39;http.client.HTTPResponse&#39;&gt;通过输出结果可以发现它是一个http.client.HTTPResponse类型的对象，它主要包含的方法有read()、readinto()、getheader(key)、getheaders()、fileno()等函数和msg、version、status、reason、debuglevel、closed等属性。得到这个对象之后，将其赋值给response，就可以用response调用这些方法和属性，以此得到返回结果和信息。如response.read().decode(“utf-8”)可以得到返回后的利用utf-8编码的网页内容，response.status可以得到响应返回结果的状态码。下面再来一个实例感受一下： 123456789&gt;&gt;&gt; import urllib.request&gt;&gt;&gt;&gt;&gt;&gt; response = urllib.request.urlopen(&quot;http://www.baidu.com&quot;)&gt;&gt;&gt; print(response.status)200&gt;&gt;&gt; print(response.getheaders())[(&apos;Date&apos;, &apos;Thu, 07 Dec 2017 14:37:26 GMT&apos;), (&apos;Content-Type&apos;, &apos;text/html; charset=utf-8&apos;), (&apos;Transfer-Encoding&apos;, &apos;chunked&apos;), (&apos;Connection&apos;, &apos;Close&apos;), (&apos;Vary&apos;, &apos;Accept-Encoding&apos;), (&apos;Set-Cookie&apos;, &apos;BAIDUID=3D72FEFAEEE60FAB2F79886A59FAC02D:FG=1; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com&apos;), (&apos;Set-Cookie&apos;, &apos;BIDUPSID=3D72FEFAEEE60FAB2F79886A59FAC02D; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com&apos;), (&apos;Set-Cookie&apos;, &apos;PSTM=1512657446; expires=Thu, 31-Dec-37 23:55:55 GMT; max-age=2147483647; path=/; domain=.baidu.com&apos;), (&apos;Set-Cookie&apos;, &apos;BDSVRTM=0; path=/&apos;), (&apos;Set-Cookie&apos;, &apos;BD_HOME=0; path=/&apos;), (&apos;Set-Cookie&apos;, &apos;H_PS_PSSID=25263_1467_21122_25178_20718; path=/; domain=.baidu.com&apos;), (&apos;P3P&apos;, &apos;CP=&quot; OTI DSP COR IVA OUR IND COM &quot;&apos;), (&apos;Cache-Control&apos;, &apos;private&apos;), (&apos;Cxy_all&apos;, &apos;baidu+90b96fddd3e4cc794d4573d45036518c&apos;), (&apos;Expires&apos;, &apos;Thu, 07 Dec 2017 14:36:39 GMT&apos;), (&apos;X-Powered-By&apos;, &apos;HPHP&apos;), (&apos;Server&apos;, &apos;BWS/1.1&apos;), (&apos;X-UA-Compatible&apos;, &apos;IE=Edge,chrome=1&apos;), (&apos;BDPAGETYPE&apos;, &apos;1&apos;), (&apos;BDQID&apos;, &apos;0xe4820d9700009820&apos;), (&apos;BDUSERID&apos;, &apos;0&apos;)]&gt;&gt;&gt; print(response.getheader(&quot;Server&quot;))BWS/1.1 可见，三个输出分别输出了响应的状态码，响应的头信息，以及通过传递一个参数来获取对应的头信息。 高级urllib.request.urlopen()使用方法 利用urlopen()方法，我们可以实现对一般网页的GET请求。如果我们想给链接传递一些参数该怎么实现呢？我们首先看一下urlopen()函数的API。 urllib.request.urlopen(url, data=None, [timeout, ]*, cafile=None, capath=None, cadefault=False, context=None) 可以发现除了第一个参数可以传递URL之外，我们还可以传递其它的内容，比如data(附加参数)，timeout(超时时间)等等。data参数是可选的，如果要添加data，它要求是字节流编码格式的内容，即bytes类型，通过bytes()函数可以进行转化，另外如果你传递了这个data参数，它的请求方式就不再是GET方式请求，而是POST。 123456import urllib.parse import urllib.request data = bytes(urllib.parse.urlencode(&#123;'word': 'hello'&#125;), encoding='utf-8') response = urllib.request.urlopen('http://httpbin.org/post', data=data) print(response.read().decode('utf-8'))#read获取的是bytes型的数据，decode可按特定编码方式编码(相当于获取响应体)。 在这里我们传递了一个参数word，值是hello。它需要被转码成bytes(字节流)类型。其中转字节流采用了bytes()方法，第一个参数需要是str(字符串)类型，需要用urllib.parse.urlencode()方法来将参数字典转化为字符串。第二个参数指定编码格式，在这里指定为utf-8。提交的网址是httpbin.org，它可以提供HTTP请求测试。http://httpbin.org/post这个地址可以用来测试POST请求，它可以输出请求和响应信息，其中就包含我们传递的data参数。运行结果如下： 12345678910111213141516171819&#123; &quot;args&quot;: &#123;&#125;, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: &#123;&#125;, &quot;form&quot;: &#123; &quot;word&quot;: &quot;hello&quot; &#125;, &quot;headers&quot;: &#123; &quot;Accept-Encoding&quot;: &quot;identity&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Content-Length&quot;: &quot;10&quot;, &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;Python-urllib/3.6&quot; &#125;, &quot;json&quot;: null, &quot;origin&quot;: &quot;112.10.180.190&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot;&#125; 我们传递的参数出现在了form中，这表明我们的python语句模拟了表单提交的方法，并以POST方式传输数据。 timeout参数 timeout参数可以设置超时时间，单位为秒，意思就是如果请求超出了设置的这个时间还没有得到响应，就会抛出异常，如果不指定，就会使用全局默认时间。它支持HTTP、HTTPS、FTP请求。下面来用一个实例感受一下： 123import urllib.request response = urllib.request.urlopen("http://httpbin.org/get",timeout=0.1) print(response.read()) 结果如下： 1234567891011121314151617During handling of the above exception, another exception occurred:Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; File &quot;/Users/sliver/anaconda3/lib/python3.6/urllib/request.py&quot;, line 223, in urlopen return opener.open(url, data, timeout) File &quot;/Users/sliver/anaconda3/lib/python3.6/urllib/request.py&quot;, line 526, in open response = self._open(req, data) File &quot;/Users/sliver/anaconda3/lib/python3.6/urllib/request.py&quot;, line 544, in _open &apos;_open&apos;, req) File &quot;/Users/sliver/anaconda3/lib/python3.6/urllib/request.py&quot;, line 504, in _call_chain result = func(*args) File &quot;/Users/sliver/anaconda3/lib/python3.6/urllib/request.py&quot;, line 1346, in http_open return self.do_open(http.client.HTTPConnection, req) File &quot;/Users/sliver/anaconda3/lib/python3.6/urllib/request.py&quot;, line 1320, in do_open raise URLError(err)urllib.error.URLError: &lt;urlopen error timed out&gt; 在这里我们设置了超时时间是0.1秒，在0.1秒过后服务器依然没有响应，于是程序抛出了urllib.error.URLError异常，错误原因是timed out。因此我们可以通过设置这个超时时间来控制一个网页如果长时间未响应就跳过它的抓取，利用try，except语句就可以实现这样的操作。 123456789import urllib.request import socket import urllib.error try: response = urllib.request.urlopen('http://httpbin.org/get',timeout=0.1) except urllib.error.URLError as e: if isinstance(e.reason, socket.timeout): print("Time out!") 在这里我们请求了http://httpbin.org/get这个测试链接，设置了超时时间是0.1秒，然后捕获了urllib.error.URLError这个异常，然后判断异常原因是超时异常，就得出它确实是因为超时而报错，打印输出了TIME OUT，当然你也可以在这里做其他的处理。运行结果如下： 1Time out! 常理来说，0.1秒内基本不可能得到服务器响应，因此输出了TIME OUT的提示。这样，我们可以通过设置 timeout这个参数来实现超时处理，有时还是很有用的。其他参数还有context参数，它必须是ssl.SSLContext类型，用来指定SSL设置。cafile和capath两个参数是指定CA证书和它的路径，这个在请求HTTPS链接时会有用。cadefault参数现在已经弃用了，默认为False。以上讲解了url.request.urlopen()方法的用法，通过这个最基本的函数可以完成简单的请求和网页抓取，如需详细了解，可以查看官方文档：https://docs.python.org/3/library/urllib.request.html urllib.request.Request()使用方法 由上我们知道利用urlopen()方法可以实现最基本的请求发起，但这几个简单的参数并不足以构建一个完整的请求，如果请求中需要加入headers等信息，我们就可以利用更强大的Request类来构建一个请求。首先我们用一个实例来感受一下Request的用法: 12345import urllib.request request = urllib.request.Request("https://www.baidu.com") response = urllib.request.urlopen(request) print(response.read().decode("utf-8")) 可以发现，我们依然是用urlopen()方法来发送这个请求，只不过这次urlopen()方法的参数不再是一个URL，而是一个Request，通过构造这个这个数据结构，一方面我们可以将请求独立成一个对象，另一方面一个请求可配置的参数将更加丰富和灵活。下面我们看一下Request都可以通过怎样的参数来构造，它的构造方法如下： urllib.request.Request(url, data=None, headers={}, origin_req_host=None, unverifiable=False, method=None) 第一个参数是请求链接，这个是必传参数，其他的都是可选参数。data参数如果要传必须传bytes(字节流)类型的，如果是一个字典，可以先用urllib.parse.urlencode()编码。headers参数是一个字典，你可以在构造Request时通过headers参数传递，也可以通过调用Request对象的add_header()方法来添加请求头。请求头最常用的用法就是通过修改User-Agent来伪装浏览器，默认的User-Agent是Python-urllib，你可以通过修改它来伪装成浏览器。origin_req_host指的是请求方的host名称或是IP地址。unverifiable指的是这个请求是否是无法验证的，默认是False。意思就是说用户没有足够权限来选择接收这个请求的结果。例如我们请求一个HTML文档中的图片，但是我们没有自动抓取图像的权限，这时unverifiable的值就是True。method是一个字符串，它用来指示请求使用的方法，比如GET，POST，PUT等等。下面我们传入多个参数构建一个Request来感受一下： 1234567891011121314from urllib import request,parse url = "http://httpbin.org/post" headers = &#123; "User-Agent":'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36', "Host":'httpbin.org' &#125; dict = &#123; "name":"Germey" &#125; data = bytes(parse.urlencode(dict),encoding="utf-8") req = request.Request(url=url,data=data,headers=headers,method="POST") response = request.urlopen(req) print(response.read().decode("utf-8")) 在这里我们通过四个参数构造了一个Request，url即请求链接，在headers中指定了User-Agent 和Host，传递的参数data用了urlencode()和bytes()方法来转成字节流，另外指定了请求方式为POST。运行结果如下： 12345678910111213141516171819&#123; &quot;args&quot;: &#123;&#125;, &quot;data&quot;: &quot;&quot;, &quot;files&quot;: &#123;&#125;, &quot;form&quot;: &#123; &quot;name&quot;: &quot;Germey&quot; &#125;, &quot;headers&quot;: &#123; &quot;Accept-Encoding&quot;: &quot;identity&quot;, &quot;Connection&quot;: &quot;close&quot;, &quot;Content-Length&quot;: &quot;11&quot;, &quot;Content-Type&quot;: &quot;application/x-www-form-urlencoded&quot;, &quot;Host&quot;: &quot;httpbin.org&quot;, &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&quot; &#125;, &quot;json&quot;: null, &quot;origin&quot;: &quot;112.10.180.190&quot;, &quot;url&quot;: &quot;http://httpbin.org/post&quot;&#125; 通过观察结果可以发现，我们成功设置了data，headers以及method参数，并完成了请求。另外headers也可以用add_header()方法来添加： 12req = request.Request(url=url, data=data, method=&apos;POST&apos;)req.add_header(&apos;User-Agent&apos;, &apos;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36&apos;) 如此一来，我们就可以更加方便地构造一个Request，实现请求的发送。 urllib.request高级特性 在上面的过程中，我们虽然可以构造Request，但是一些更高级的操作，比如Cookies处理，代理该怎样来设置？接下来就需要更强大的工具Handler登场了。简而言之你可以把它理解为各种处理器，有专门处理登录验证的，有处理 Cookies 的，有处理代理设置的，利用它们我们几乎可以做到任何HTTP请求中所有的事情。首先介绍下urllib.request.BaseHandler，它是所有其他Handler的父类，它提供了最基本的 Handler的方法，例如efault_open()、protocol_request()等。接下来就有各种Handler类继承这个BaseHandler，列举如下： HTTPDefaultErrorHandler：用于处理HTTP响应错误，错误都会抛出HTTPError类型的异常。 HTTPRedirectHandler：用于处理重定向。 HTTPCookieProcessor：用于处理Cookie 。 ProxyHandler：用于设置代理，默认代理为空。 HTTPPasswordMgr：用于管理密码，它维护了用户名密码的表。 HTTPBasicAuthHandler：用于管理认证，如果一个链接打开时需要认证，那么可以用它来解决认证问题。 另外还有其他的Handler，可以参考官方文档：https://docs.python.org/3/library/urllib.request.html#urllib.request.BaseHandler 另外一个比较重要的就是OpenerDirector，我们可以称之为Opener，我们之前用过urllib.request.urlopen()这个方法，实际上它就是一个Opener。那么为什么要引入Opener呢？因为我们需要实现更高级的功能，之前我们使用的Request、urlopen()相当于类库为你封装好了极其常用的请求方法，利用它们两个我们就可以完成基本的请求，但是现在不一样了，我们需要实现更高级的功能，所以我们需要深入一层，使用更上层的实例来完成我们的操作。所以，在这里我们就用到了比调用urlopen()的对象的更普遍的对象，也就是Opener。Opener可以使用open()方法，返回的类型和urlopen()如出一辙。那么它和Handler有什么关系？简而言之，就是可以利用Handler来构建Opener。 认证 我们先用一个实例来感受一下： 1234567import urllib.request auth_handler = urllib.request.HTTPBasicAuthHandler() auth_handler.add_password(realm='PDQ Application', uri='https://mahler:8092/site-updates.py', user='klem', passwd='kadidd!ehopper') opener = urllib.request.build_opener(auth_handler) urllib.request.install_opener(opener) urllib.request.urlopen('http://www.example.com/login.html') 此处代码为实例代码，用于说明Handler和Opener的使用方法。在这里，首先实例化了一个HTTPBasicAuthHandler对象，然后利用add_password()添加进去用户名和密码，相当于建立了一个处理认证的处理器。接下来利用urllib.request.build_opener()方法来利用这个处理器构建一个Opener，那么这个Opener在发送请求的时候就具备了认证功能了。然后利用Opener的open()方法打开链接，就可以完成认证了。 代理 如果添加代理，可以这样做： 12345678import urllib.request proxy_handler = urllib.request.ProxyHandler(&#123; 'http': 'http://218.202.111.10:80', 'https': 'https://180.250.163.34:8888' &#125;) opener = urllib.request.build_opener(proxy_handler) response = opener.open('https://www.baidu.com') print(response.read()) 此处代码为实例代码，用于说明代理的设置方法，代理可能已经失效。 在这里使用了ProxyHandler，ProxyHandler的参数是一个字典，key是协议类型，比如HTTP还是HTTPS等，value是代理链接，可以添加多个代理。然后利用build_opener()方法利用这个Handler构造一个Opener，然后发送请求即可。 Cookies设置 我们先用一个实例来感受一下怎样将网站的Cookie获取下来。 12345678import http.cookiejar, urllib.request cookie = http.cookiejar.CookieJar() handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open('http://www.baidu.com') for item in cookie: print(item.name+"="+item.value) 首先我们必须声明一个CookieJar对象，接下来我们就需要利用HTTPCookieProcessor来构建一个handler，最后利用build_opener方法构建出opener，执行open()即可。运行结果如下： 123456BAIDUID=2B835BFCEDF4325F88D0C6C3A4EBD649:FG=1BIDUPSID=2B835BFCEDF4325F88D0C6C3A4EBD649H_PS_PSSID=1427_24569_21091_18559_25178PSTM=1512660072BDSVRTM=0BD_HOME=0 可以看到输出了每一条Cookie的名称还有值。不过既然能输出，那可不可以输出成文件格式呢？我们知道很多Cookie实际也是以文本形式保存的.答案当然是肯定的，我们用下面的实例来感受一下： 12345678import http.cookiejar, urllib.requestfilename = 'cookie.txt' cookie = http.cookiejar.MozillaCookieJar(filename) handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open('http://www.baidu.com') cookie.save(ignore_discard=True, ignore_expires=True) 这时的CookieJar就需要换成MozillaCookieJar，生成文件时需要用到它，它是CookieJar的子类，可以用来处理Cookie和文件相关的事件，读取和保存Cookie，它可以将Cookie保存成Mozilla型的格式。运行之后可以发现生成了一个cookie.txt文件。内容如下： 12345678910# Netscape HTTP Cookie File# http://curl.haxx.se/rfc/cookie_spec.html# This is a generated file! Do not edit..baidu.com TRUE / FALSE 3660143901 BAIDUID 96CAB1FCD2CD9F4D304DE943A7018842:FG=1.baidu.com TRUE / FALSE 3660143901 BIDUPSID 96CAB1FCD2CD9F4D304DE943A7018842.baidu.com TRUE / FALSE H_PS_PSSID 1453_19034_21117_17001_25177.baidu.com TRUE / FALSE 3660143901 PSTM 1512660254www.baidu.com FALSE / FALSE BDSVRTM 0www.baidu.com FALSE / FALSE BD_HOME 0 另外还有一个LWPCookieJar，同样可以读取和保存Cookie，但是保存的格式和MozillaCookieJar的不一样，它会保存成与libwww-perl的Set-Cookie3文件格式的Cookie。那么在声明时就改为cookie = http.cookiejar.LWPCookieJar(filename)生成的内容如下：由此看来生成的格式还是有比较大的差异的。 1234567#LWP-Cookies-2.0Set-Cookie3: BAIDUID=&quot;A84BFF86A8AACB4C3B4CD734F7D11193:FG=1&quot;; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; expires=&quot;2085-12-25 18:40:37Z&quot;; version=0Set-Cookie3: BIDUPSID=A84BFF86A8AACB4C3B4CD734F7D11193; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; expires=&quot;2085-12-25 18:40:37Z&quot;; version=0Set-Cookie3: H_PS_PSSID=25292_1433_24885_21104_18560_17001_25178_20930; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; discard; version=0Set-Cookie3: PSTM=1512660390; path=&quot;/&quot;; domain=&quot;.baidu.com&quot;; path_spec; domain_dot; expires=&quot;2085-12-25 18:40:37Z&quot;; version=0Set-Cookie3: BDSVRTM=0; path=&quot;/&quot;; domain=&quot;www.baidu.com&quot;; path_spec; discard; version=0Set-Cookie3: BD_HOME=0; path=&quot;/&quot;; domain=&quot;www.baidu.com&quot;; path_spec; discard; version=0 那么生成了Cookie文件，怎样从文件读取并利用呢？下面我们以LWPCookieJar格式为例来感受一下： 12345678import http.cookiejar, urllib.requestcookie = http.cookiejar.LWPCookieJar() cookie.load('cookie.txt', ignore_discard=True, ignore_expires=True) handler = urllib.request.HTTPCookieProcessor(cookie) opener = urllib.request.build_opener(handler) response = opener.open('http://www.baidu.com') print(response.read().decode('utf-8')) 前提是我们首先利用上面的方式生成了LWPCookieJar格式的Cookie，然后利用load()方法，传入文件名称，后面同样的方法构建handler和opener即可。运行结果正常输出百度网页的源代码。 小结 urllib是python3中写爬虫程序的得力助手，它很好，当然，也有比它更好的。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Tips</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3爬虫之基本概念]]></title>
    <url>%2F2017%2F12%2F07%2FPython3%E7%88%AC%E8%99%AB%E4%B9%8B%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[学了python也有一段时间了，这几天才开始去接触爬虫，再一次感叹python的强大。而爬虫是之前一直接触的名词，但自以为一直没有学好基础，就一直没有去接触，在这次在学习的过程中，终于揭开了它的面纱。 爬虫，顾名思义，就是一只会爬行的虫子，如果把网络比喻成一张网，爬虫就是爬行在这张网上的小蜘蛛，网所及之处，都是它能到达的地方。顺到网页所在之处，获取需要的大量数据，就是爬虫的意义所在。简而言之，它就是一个能请求网站并提取其中的数据的自动化程序。 爬虫基本流程 发起请求：通过HTTP库向目标站点发起请求，即发送一个Request，请求可以包含额外的headers、data等信息，等待服务器响应。 获取响应内容：如果服务器能正常响应，会得到一个Response，Response的内容便是所要获取的页面内容，类型可能有HTML，Json字符串，二进制数据（如图片视频）等类型。 解析内容：得到的内容可能是HTML，可以用正则表达式，网页解析库进行解析，可能是Json，可以直接转为Json对象解析，可能是二进制数据，可以做保存或者进一步的处理。 保存数据：保存形式多样，可以保存为文本，也可以保存至数据库，或者保存至数据库，或者保存特定格式的文件。 那么什么是Request和Response呢？ 首先要了解一下HTTP协议，这里简单说一下。在HTTP协议中，请求访问文本或图像资源的一端称为客户端，而提供资源响应的一端称为服务器端。在我们用浏览器访问一个网页时，浏览器和远在云端的服务器其实就分别扮演着客户端和服务端的角色。 当浏览器发送消息给我们请求的网页所在的服务器时，这个过程就是HTTP Request。 服务器收到浏览器发送的消息后，能够根据浏览器发送消息的内容，采取相应处理，然后把消息传回给浏览器，这个过程叫做HTTP Response。 浏览器收到服务器的Response信息后，会对信息进行相应处理，然后展示。 下面分别来看看Request和Response的内容 Request 请求方式：主要有GET、POST两种请求类型，另外还有不常用的HEAD、PUT、DELETE、OPTIONS请求类型等。 请求URL：URL全称为统一资源定位符，它就像人们可以通过自己所在的地址来定位自己一样，URL通过资源所在的位置来唯一确定资源，如一个网页文档、一张图片、一个视频都能用URL来唯一确定。 请求头：Headers包含请求时所包含的头部信息，如User-Agent、Host、Cookies等信息。 请求体：请求时额外携带的数据，如在网页提交时需要提交表单信息data。 Response 响应状态：有多种表示响应状态的状态码，如200表示成功，301表示跳转，404表示找不到页面，502表示服务器发生错误。（2XX成功，3XX重定向，4XX客户端错误，5XX服务器错误） 响应头：如内容类型、内容长度、服务器信息、设置Cookies等。 响应体：这是Response种最重要的部分，包含了请求资源的内容，如网页的HTML、二进制信息图片视频等。 12345import requestshtml = requests.get("http://www.baidu.com") #一个普通的GET请求print(html.text) print(html.status_code) #返回结果状态码 如何处理所得数据呢？（网页、图片、视频等其他数据） 话不多少，直接处理二进制数据。 用Json解析。 “只是用来写”的正则表达式。 BeautifulSoup，强大的python第三方解析库。 PyQuery、XPath等。 当然，有时候我们通过HTTP访问库访问网页的结果与浏览器加载后所看到的不一样，这就涉及到了Javascript的渲染问题。可以通过分析Ajax请求、Selenium/WebDriver、Splash、PyV8和Ghost.py等来解决。 12345from selenium import webdriverdriver = webdriver.Chrome()driver.get('http://www.taobao.com') #可驱使Chrome浏览器去访问网页print(driver.page_source) 怎样保存数据呢？ 文本：纯文本、Json、Xml等。 关系型数据库：如Mysql、Oracle、SQL Server等具有结构化表结构形式存储。 非关系型数据库：如MongoDB、Redis等Key-Value形式存储。 二进制文件：如图片、视频、音频等直接保存成特点格式即可。 END 基本概念就是这些了，HTTP协议想了解得更清楚一些的话可以去看看图解HTTP，另外用python写爬虫需要安装一些第三方库，可使用pip方法下载，以后再补充好啦。]]></content>
      <categories>
        <category>爬虫</category>
      </categories>
      <tags>
        <tag>Tips</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown使用教程]]></title>
    <url>%2F2017%2F10%2F30%2FMarkdown%2F</url>
    <content type="text"><![CDATA[Markdown 的目标是实现「易读易写」。 可读性，无论如何，都是最重要的。一份使用 Markdown 格式撰写的文件应该可以直接以纯文本发布，并且看起来不会像是由许多标签或是格式指令所构成。Markdown 语法受到一些既有 text-to-HTML 格式的影响，包括 Setext、atx、Textile、reStructuredText、Grutatext 和 EtText，而最大灵感来源其实是纯文本电子邮件的格式。总之， Markdown 的语法全由一些符号所组成，这些符号经过精挑细选，其作用一目了然。比如：在文字两旁加上星号，看起来就像强调。Markdown 的列表看起来，嗯，就是列表。Markdown 的区块引用看起来就真的像是引用一段文字，就像你曾在电子邮件中见过的那样。 以上文字引用自Markdown 语法说明(简体中文版) 显而易见，Markdown有以下优点： 它是纯文本发布的，所以兼容性很强，可以用所有的文本编辑器打开并编写。 它让你更专注于文字的内容而不是无谓的排版。 它的格式转换方便，你可以轻松的将Markdown的文本转换为html、电子书等。 它的标记语法有极好的可读性。 那就来学学吧🤔 标题 一篇文章都是从标题开始的，为了得到如上所示的标题，我们需要在Markdown编译器里输入： 1## 标题 #号之后记住要加上空格，##两个井号代表这是一个二级标题。 123456# 一级标题## 二级标题### 三级标题#### 四级标题##### 五级标题###### 六级标题 现在看看其他标题的大小： 一级标题二级标题三级标题四级标题五级标题六级标题粗体和斜体 有时候我们想对文章的几个字或者一段话进行强调，那强调的一般方法就是加粗了。Markdown的粗体和斜体的表示非常简单，用一对**包含一段文字就是粗体的表示方法，用一对*包含一段文字就是斜体的表示方法。 1**看我是不是变粗啦** *看我是不是变斜啦* 看我是不是变粗啦 看我是不是变斜啦 列表 列表分为无序列表和有序列表。在Markdown下，只要在文字前加上-或*即可变为无序列表，在文字前加上1. 2. 3.即可变为有序列表。划重点：要在符号和文字之间加上一个空格。 1234567891011* 一* 二* 三- 一- 二- 三1. 一2. 二3. 三 一 二 三 一 二 三 一 二 三 也可以对列表进行嵌套： 12345* 第一部分 * 第一小节（一般嵌套是缩进是四个空格~） * 第一小小节 * 第二小小节 * 第二小节 第一部分 第一小节（一般嵌套是缩进是四个空格~） 第一小小节 第二小小节 第二小节 *可用+ -替代。 引用 文章中引用一段话也是很普遍的，就像本篇教程首段也引用了Markdown官方的宗旨。引用时，只需要在文字前加入&gt;大于号即可。 1&gt;你是我唯一想要的了解。——《七里香》 你是我唯一想要的了解。——《七里香》 插入链接和图片 美观富有哲思的文章里少不了图片和链接。使用[链接名称](链接地址)的格式插入链接，图片与链接大部分相同，只是多在前面加了一个!,也就是使用![图片名称](图片地址)的格式插入图片。 123[百度一下，你就知道](https://www.baidu.com/)![柚子](Markdown/favicon.ico) 百度一下，你就知道 描述图片位置的时候我使用了相对位置描述图片相对于我的这篇文章的位置。 分隔线 为了清晰划分文章的层次，可以使用分隔线。使用连续三个***或---启用分隔线。 123***--- 如上所示👆 代码 身为一个程序员，在描述命令行或者代码块时，都可以使用Markdown优雅的引用代码框。 当只是引用少量的只是一行的代码时，可以用一对 反引号`包围代码： 1`hexo server` hexo server 当引用数量较大的行数较多的代码时，可以用一对三个反引号`包围代码块： 12def Hello(): print("Hello World!") 还可以直接将代码块缩进四个空格或一个制表符引入代码框（如果是在嵌套列表中进行缩进，是要缩进4×当前属于第几层嵌套，如果是第二层嵌套就应该是缩进八个空格，以此类推）： Hello World! 贴上部分编写源码。 这里在三引号那里写入Python是为了表示所插入代码是Python语言编写的，这样可以使渲染引擎在此代码块区域对代码进行更好的渲染。另外在使用三引号括起代码块或缩进引用代码框时，最好在代码块上下两行各空一行且三引号最好放在代码上下行，以防不可抗力因素。（单引号括起就不需要空行了，可直接内嵌在文字中。） PS：反引号是在英文模式下的~键打出来的。 并且在hexo next主题渲染后发现单引号括起的代码只是简单的灰底，三引号括起的代码是带有序号的黑底代码框，四空格缩进的代码是无序号的黑底代码框，也许Markdown最终的显示跟渲染引擎有很大的关系吧… 小贴士 Markdown 支持以下这些符号前面加上反斜杠来帮助插入普通的符号： 123456789101112\ 反斜线 ` 反引号 * 星号 _ 底线 &#123;&#125; 花括号 [] 方括号 () 括弧 # 井字号 + 加号- 减号. 英文句点! 惊叹号 类似c语言的转义字符，满足\特殊字符的格式即可引用在文中了。 在写一篇文章时，我们往往想要在首行空两个空格，这时可以在段首加入&amp;emsp; &amp;emsp;来输入两个空格。 添加空行是可以结束先前的格式状态的，所以在想要改变格式，如插入列表或者引入代码框时，最好都添加一个空行。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Tips</tag>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+GitHub+Mac安装教程]]></title>
    <url>%2F2017%2F10%2F30%2FHexo%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[其实这个博客用了半天就搭好了。但是在主题和个人偏好设置方面真的是很痛苦，不断钻研最后才弄得算是拿得起台面了一些，现在分享一下我的经验。 首先，什么是Hexo？什么是静态博客呢？ Hexo出自台湾大学生 tommy351 之手，是一个基于 Node.js 的静态博客程序，其编译上百篇文字只需要几秒。hexo生成的静态网页可以直接放到GitHub Pages，BAE，SAE等平台上。 而静态博客相较于动态博客，它编译之后是纯html页面，支持它的环境十分好找，如GitHub Pages；而选择在v、VPS上面搭建动态博客，这些VPS供应商往往是“免费的不稳定，稳定的不免费”。那么，可以利用免费的资源搭载属于自己的稳定的个人博客，何乐而不为呢？ 步骤 安装Git 其实mac上只要安装了Xcode也就默认安装了git，这里就直接推荐各位去AppStore下载Xcode了，顺便配置一下即可👉Xcode:在 Mac App Store 上的内容 另外推荐一下廖大的教程：廖雪峰git教程 安装Node.js 使用brew安装node.js，安装brew之前要先安装命令行工具，如果安装了Xcode也就不需要安装了，所以建议还是先直接安装Xcode吧…安装完Xcode之后按组合键：command+空格打开Spotlight搜索，输入终端打开终端。 安装Homebrew（终端粘贴如下代码即可）。 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; 安装完brew后，终端输入brew install node安装node.js即可。 安装Hexo 同理，在终端一行一行输入如下命令：123456sudo npm install -g hexo #下载安装Hexo。mkdir blog #在当前位置新建blog文件夹。cd blog #切换到blog目录。hexo init #初始化。hexo generate #生成静态文件。hexo server #启动本地服务，进行文章预览调试。 本地调试 现在打开http://localhost:4000就能看到默认的Hexo界面了。 但是，这还不够，因为你想展示你的博客给所有人看，所以你还要将你的页面托管起来。 注册GitHub账号与配置SSH 参考教程利用SSH建立远程链接 配置GitHub 建立Repository，建立与你用户名对应的仓库，仓库名必须为[your-name.github.io]，这是固定写法。 Spotlight搜索我们之前创建的blog文件夹，里面有_config.yml文件，打开找到deploy字段，修改为： 1234deploy: type: git repo: https://github.com/your-name/your-name.github.io.git branch: master 保存以上修改后在终端输入 1npm install hexo-deployer-git --save 成功后再执行命令： 1hexo deploy 然后在浏览器中输入http://your-name.github.io/会发现你的博客可以通过这个网址打开了。 PS：记得把your-name改成你的github的账户名。 博客 博客部署 以后部署到GitHub Pages的步骤，可在终端按以下三步来进行。 123hexo clean #清除缓存文件 (db.json) 和已生成的静态文件 (public)。 hexo generate #生成静态页面至public目录。hexo deploy #将生成的目录部署到GitHub上。 当想在本地调试时，可以在终端切换到blog文件夹，使用hexo server命令启动服务器。默认情况下，访问网址为： http://localhost:4000/。即可预览产生的博客界面。 常用命令👇：1234hexo new &quot;postname&quot; #新建文章hexo new page &quot;pagename&quot; #新建页面hexo help #查看帮助hexo version #查看Hexo的版本 博客主题 配置好博客后也许你会觉得你的博客界面并不靓丽，这就需要强大的主题了，可在以下三个链接中了解一下主题。 知乎：Hexo有哪些好看的主题？ 主题 | Hexo 还有我现在用的主题 NexT | Pisces 主题配置 每个主题都是有文档对其进行详细的描述的，这里不细说，发掘配置也是搭建这个博客的乐趣所在哈。 后记 搭好并配置完这个博客的时候还是很开心的，像是将之前学的git、html和命令行知识进行了融会贯通一般。小宝很可爱，JavaScript很有趣，Holen学长很cool，前端路漫漫，继续向前看吧。]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>Tips</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[macOS常用命令]]></title>
    <url>%2F2017%2F10%2F30%2F%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[先来讲讲macOS和Unix还有Linux的关系 Unix最早是在贝尔实验室开发的，是一个强大的多用户、多任务操作系统，支持多种处理器架构，按照操作系统的分类，属于分时操作系统。为主要的工作站平台和重要的企业操作平台。它主要安装在巨型计算机、大型机上作为网络操作系统使用，也可用于个人计算机和嵌入式系统。曾经是服务器操作系统的首选。 Linux是一类类Unix计算机操作系统的统称。Linux操作系统的内核的名字也是“Linux”。Linux操作系统也是自由软件和开放源代码发展中最著名的例子。严格来讲，Linux这个词本身只表示Linux内核，但在实际上人们已经习惯了用Linux来形容整个基于Linux内核，并且使用GNU 工程各种工具和数据库的操作系统。Linux得名于计算机业余爱好者Linus Torvalds。一般可以认为，Linux是一套自由使用（一般可以免费使用）和自由传播的类Unix操作系统。这个系统是由世界各地成千上万的程序员设计和实现的。其目的是建立不受任何商品化软件的版权制约、全世界都能自由使用的Unix兼容产品。实际上，Linux仅仅的Linux操作系统中的核心（kernel）。 Mac系统是苹果机专用系统，是基于Unix内核的图形化操作系统，一般情况下在普通pc上无法安装的操作系统。 所以说linux是兼容unix的，或者说是Linus写的一种开源的类unix系统，而macOS的内核其实就是unix。所以在同一种shell环境下，macOS和Linux的许多命令是共通的，这里所说的macOS常用命令其实就是兼容大部分Linux系统的终端命令。 两种路径：绝对路径和相对路径 再来说说比较重要的路径 绝对路径：完整描述一个文件的位置，总是以斜杠（/）（forward slash）开头。例如/Users/michelle/Public/Drop Box。相对路径：只描述一部分位置信息，它和你在 command line 目前的目录有关。当你打开新的 Terminal 程序时，command line 会话的目录应该是你的 home folder。这时上面例子文件夹的相对路径写作Public/Drop Box。显然它从当前目录开始。和html类似，你也可以使用两个点（“..”）来代表父目录，这样你就可以用相对路径表示上级或同级目录了。例如你可以输入cd ..甚至cd ../..来返回上级目录。 常用命令💻 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364ls (list directory contents)列出当前目录的内容ls -l 列出当前目录文件详细信息l(list)ls -a 列出当前目录下所有文件及目录，包括隐藏的文件和目录(a=all)mkdir 创建目录mkdir -p 创建目录，若无父目录，则创建p(parent) rmdir 删除目录(rmdir dir)cd (change directory)改变当前目录到指定目录(cd .. 返回上一目录)touch 创建空文件，可touch test.txt或者touch 文件夹名/test.txt(在指定文件夹创建空文件)echo 创建带有内容的文件cat 查看文件内容cp 复制文件或目录(cp file1 file2)cp -r 复制目录内所有内容mv 改变文件名或移动其所在目录(mv file1 file2)mv -r 移动目录到另一目录(mv dir1 dir2) rm 删除文件rm -r 递归删除，可删除子目录及文件rm -f 强制删除rm -rf 删除文件夹 pwd (print working directory)显示当前目录的绝对路径vim 创建并编辑文件(先按i插入文字，完成后按esc再按：wq保存并退出)（esc :q! 放弃修改编辑内容直接退出）control+d 退出python3vim test.c 编写c文件gcc test.c 编译c文件./a.out 运行c文件control+C 中止一个错误的或者发疯的命令control+L 清屏Mac下常见vim的命令： 1. 在默认的&quot;指令模式&quot;下按 i 进入编辑模式 2. 在非指令模式下按 ESC 返回指令模式 3. 在&quot;指令模式&quot;下输入: :w 保存当前文件 :q 退出编辑,如果文件为保存需要用强制模式 :q! 强制退出不保存修改 :wq 组合指令, 保存并退出 4. 在“指令模式”下移动: h 左 j 下 k 上 l 右 shutdown -r 关机重启 -h 关机不重启 now 立刻关机halt 关机reboot 重启find 在文件系统中搜索某文件wc 统计文本中行数、字数、字符数grep 在文本文件中查找某个字符串tree 树形结构显示目录，需要安装tree包ln 创建链接文件more、less 分页显示文本文件内容head、tail 显示文件头、尾内容ctrl+alt+F1 命令行全屏模式 偶然看到这个博客，顺便贴上：Mac OS X Terminal 101：终端使用初级教程 未完待续。]]></content>
      <categories>
        <category>命令</category>
      </categories>
      <tags>
        <tag>Tips</tag>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Disneyland]]></title>
    <url>%2F2017%2F10%2F25%2FDisneyland%2F</url>
    <content type="text"><![CDATA[✨Disneyland游玩攻略✨ 简述🦄 上海迪士尼乐园目前共分六个主题园区，分别是：以米奇和他的欢乐伙伴们为主题设计的迎宾大道 — 米奇大街；展现自然奇妙又充满想象力的花园设计主题区 — 奇想花园；完美呈现迪士尼电影世界之 — 梦幻世界；探寻神秘远古部落的冒险乐园 — 探险岛；惊险热闹的海盗世界 — 宝藏湾；科技打造的未来感满满的酷炫天地 — 明日世界。（在建的第七个主题园区 — 玩具总动园 将于2018年开放)除了遍布商店和餐馆的米奇大道外，每个园区都设置了与其主题相对应的游乐项目，各具特色，充满无穷的想象力和无尽的乐趣。除了亲身体验的游乐项目，各园区还有精心安排的表演秀，为你带来一场场视听盛宴。此外，各园区都有一些迪士尼经典人物形象出没，有专门的“与迪士尼朋友见面”环节，看到自己喜欢的卡通形象一定要记得合影留念哦。 步骤🎃 1 门票：抽奖得到了一张并低价向另一名中奖者买。 2 时间：工作日九点开园，节假日八点开园，最好提前40分钟，所以应该要7.20到。 3 物品：身份证，现金（要有硬币），雨伞（遮阳挡雨），充电宝，数据线，充电器，洗漱用品，舒服的鞋子，帽子，水杯，未开封的零食，雨衣（如果想玩雷鸣山漂流的话）。 4 网页：迪士尼官网 5 APP: 导航软件(百度地图等)，迪士尼度假区app，乐拍通app（找准位置，安排行程很重要）。 6 交通：迪士尼乐园在上海地铁11号线的终点站，交通方便。 7 酒店：迪士尼附近的酒店都很贵，其实找个地铁11号线沿线附近的酒店就可以了。 PS：开封后的饮料、牛奶和自拍杆都不能带入院内。 正篇☀️ 入园后，记得拿好门票、乐园指南和时间表。门票用来取FP卡（快速通道卡），乐园指南里面有详细的地图和项目介绍，时间表用来查看各个演出的时间。左边右边米奇大道都不要停留，也不要被一进门被光鲜的玩具们拖慢了脚步。立刻飞奔向明日世界附近的游客中心领取创极速光轮的快速通行证才是最重要的！ 🌟一定要领 FP！领 FP！领 FP！重要的事说三遍！ （当然如果人特别多的话就直接跑去排队，因为这时候排队拿卡一般只能排到下午的时间。） FP卡在各区域的快速卡领取点领取，领取点可以在入园指南的地图里找。若有什么不懂的，可以直接问机器附近的工作人员。 FP是高效玩转迪士尼的制胜法宝，一些热门景点经常要排队三四个小时，但是领了FP后，就可以在它指定的时间范围内直接去玩，不用排队。 由于一张门票一次只能领一张FP，一张FP只能作用于一个景点，所以建议不要浪费，还是用在创极速光轮或者飞跃地平线这种排队排到天荒地老的大项目上。预约过FP后就要再过两个小时后才能预约下一个项目，这个时候如果想要预约第二个项目，就要看看有没有运气了。因为FP每天是有数量限制的，派完为止，一般中午后就领不到了。 News：9月7日上海迪士尼度假区发布，将在今年秋季推出电子版快速通行证，只需下载官方app，走过入园闸机后使用app扫描关联门票或季卡，即可领取电子版快速通行证，无需再往来于游客服务中心。两次领取间隔为2小时，或前一张快速通行证已使用后才能领取第二张，先到先得，发完为止。游客将能以更高效、灵活的方式享受迪士尼快速通行证服务，且无需额外付费。届时，游客可以通过上海迪士尼度假区官方手机应用程序（app）获取电子版迪士尼快速通行证，而无需匆忙地来往于指定的游客服务中心领取。游客在入园后，可把已激活的乐园门票与手机应用程序关联，按照提示进行浏览、选择及预约迪士尼快速通行证，并可随时查看快速通行证的使用时间。使用时，游客在选定景点的快速通行证入口扫描他们的手机或乐园门票上的二维码，在快速通行证以及与乐园门票相关联的游客照片验证成功后，游客便可快捷地体验景点。 划重点⚡️ FP不用再去游客中心排队领取了，也就是说进园后不必再不顾一切地向右跑了！ 迪士尼快速通行证每日限量发行，不可转让。两次领取间隔为2小时，或前一张快速通行证已使用后才能领取第二张，先到先得，发完为止。也就是说使用你的FP在验票时一定要用关联本人的门票，其次，虽然不用再往右跑了，但激活门票后也要在app上拼手速抢热门项目的FP啊！而且要密切关注下一次领FP的时间。 FP变成了电子版，也就是说你不会再手持一张纸质版的快速通行证进行验票了，所有的FP都与你的门票相关联，走FP通道验票验的也是你的门票。 游客中心领FP的传统方法没有被废，如果你想，还是可以去那里领，在自助机器上扫描门票，电子版FP就被关联上了。1234567FP能用的7个项目： 明日世界：创极速光轮⭐️、巴斯光年星际营救 探险岛：飞跃地平线⭐️、雷鸣山漂流 梦幻世界：小飞侠天空奇遇、七个小矮人矿山车、小熊维尼历险记 单人通道（人太多时可选择）： 创极速光轮、雷鸣山漂流、 加勒比海盗-沉落宝藏之战、七个小矮人矿山车 未完待续。]]></content>
      <categories>
        <category>生活</category>
      </categories>
      <tags>
        <tag>Disneyland</tag>
        <tag>Life</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2017%2F10%2F21%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
      <categories>
        <category>命令</category>
      </categories>
      <tags>
        <tag>Tips</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
